{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":10950387,"sourceType":"datasetVersion","datasetId":6808865}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PS5E3: Models_with_Feature_Engineering_v1","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.153181Z","iopub.execute_input":"2025-03-25T01:02:53.153577Z","iopub.status.idle":"2025-03-25T01:02:53.163645Z","shell.execute_reply.started":"2025-03-25T01:02:53.153539Z","shell.execute_reply":"2025-03-25T01:02:53.162655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic data handling\nimport pandas as pd\nimport numpy as np\n\n# Visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Data preprocessing\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n\n# Model evaluation & validation\nfrom sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n\n# Machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Boosting frameworks\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\n# Optimization\nimport optuna\n\n# Deep learning (TensorFlow/Keras)\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.164850Z","iopub.execute_input":"2025-03-25T01:02:53.165235Z","iopub.status.idle":"2025-03-25T01:02:53.179456Z","shell.execute_reply.started":"2025-03-25T01:02:53.165198Z","shell.execute_reply":"2025-03-25T01:02:53.178420Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# Load competition data\n# - Training dataset\ntrain_data = pd.read_csv('/kaggle/input/playground-series-s5e3/train.csv').set_index('id')\n\n# - Testing dataset\ntest_data = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv').set_index('id')\n\n# Load original data (Hong Kong rainfall dataset)\noriginal = pd.read_csv(\"/kaggle/input/hongkongrainfall/hongkong.csv\", encoding='latin-1')\n\n# Load submission template\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s5e3/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.180501Z","iopub.execute_input":"2025-03-25T01:02:53.180837Z","iopub.status.idle":"2025-03-25T01:02:53.224441Z","shell.execute_reply.started":"2025-03-25T01:02:53.180799Z","shell.execute_reply":"2025-03-25T01:02:53.223321Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EDA Strategy:\n1. First, look briefly at original data to get more insights about the competition data\n2. Second, look closely at competition data (train data)\n\n## Variable Descriptions:\n* **Day**: Sequential identifier for observations\n* **Pressure**: Atmospheric pressure measurement (unit: hPa)\n* **Maxtemp**: Daily maximum temperature (unit: ¬∞C)\n* **Temperature**: Daily average temperature (unit: ¬∞C)\n* **Mintemp**: Daily minimum temperature (unit: ¬∞C)\n* **Dewpoint**: Dew point temperature (unit: ¬∞C)\n   * Temperature at which water vapor in the air condenses into dew\n   * Closely related to humidity - smaller difference between temperature and dewpoint indicates higher humidity\n   * Important indicator for rainfall prediction\n* **Humidity**: Relative humidity ratio\n* **Cloud**: Cloud coverage ratio\n* **Sunshine**: Hours of sunshine\n* **Winddirection**: Wind direction (unit: degrees)\n* **Windspeed**: Wind speed (unit: km/h)\n* **Rainfall**: Target variable - indicates rainfall occurrence (1) or non-occurrence (0)","metadata":{}},{"cell_type":"code","source":"# Print basic dataset information\nprint(\"\\nData shape (rows, columns):\")\nprint(original.shape)\n\n# Display column names\nprint(\"\\nColumn information:\")\nprint(original.columns)\n\n# Preview first 5 rows\nprint(\"\\nFirst 5 rows of data:\")\nprint(original.head())\n\n# Summary statistics for numerical columns\nprint(\"\\nStatistical information:\")\nprint(original.describe())\n\n# Check data types for each column\nprint(\"\\nData type information:\")\nprint(original.dtypes)\n\n# Check for missing values in each column\nprint(\"\\nMissing value check:\")\nprint(original.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.225544Z","iopub.execute_input":"2025-03-25T01:02:53.225922Z","iopub.status.idle":"2025-03-25T01:02:53.275199Z","shell.execute_reply.started":"2025-03-25T01:02:53.225892Z","shell.execute_reply":"2025-03-25T01:02:53.274100Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Explore rainfall data\nprint(\"Rainfall data type:\", original['rainfall'].dtype)\nprint(\"Unique rainfall values:\", original['rainfall'].unique())\nprint(\"Rainfall value distribution:\\n\", original['rainfall'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.276239Z","iopub.execute_input":"2025-03-25T01:02:53.276642Z","iopub.status.idle":"2025-03-25T01:02:53.287151Z","shell.execute_reply.started":"2025-03-25T01:02:53.276604Z","shell.execute_reply":"2025-03-25T01:02:53.286040Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Discrepancies Between Original Data and Competition Data\n\n#### 1. Data Source\n* Competition data combines portions of Hong Kong weather data from 2015 and 2016\n* Not complete annual data, but a mix of January-July 2016 and August-December 2015\n\n#### 2. Variable Structure Differences\n* Original data: Contains additional variables such as 'year', 'month', 'low visibility hour', 'radiation', 'evaporation'\n* Competition data: Selectively uses only a subset of variables\n\n#### 3. Missing Value Inconsistencies\n* Original data: Missing values in 'low visibility hour'(1), 'evaporation'(3), 'windspeed'(1)\n* Competition data: One missing value in 'winddirection' in the test set\n\n#### 4. Data Quality Issues\n* According to forum discussions, 'winddirection' and 'windspeed' values don't match the original\n* Original 'rainfall' variable has diverse values: (no rain), `ÂæÆÈáè`(trace amounts), numeric values (0.1~52.1)\n* Analysis of original data: '-' (1351 instances of no rain), `ÂæÆÈáè`/`√é¬¢√Å¬ø` (770 instances for trace amounts), and numeric values ranging from 0.1 to 52.1 (total of 439 instances with measurable rainfall)\n* In the competition, all rainfall information is binarized to simply 0 (no rain) and 1 (rain)","metadata":{}},{"cell_type":"code","source":"# Explore competition training data\nprint(\"\\nData shape (rows, columns):\")\nprint(train_data.shape)\n\n# Display column names\nprint(\"\\nColumn information:\")\nprint(train_data.columns)\n\n# Preview first 5 rows\nprint(\"\\nFirst 5 rows of data:\")\nprint(train_data.head())\n\n# Summary statistics for numerical columns\nprint(\"\\nStatistical information:\")\nprint(train_data.describe())\n\n# Check data types for each column\nprint(\"\\nData type information:\")\nprint(train_data.dtypes)\n\n# Check for missing values in each column\nprint(\"\\nMissing value check:\")\nprint(train_data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.288271Z","iopub.execute_input":"2025-03-25T01:02:53.288721Z","iopub.status.idle":"2025-03-25T01:02:53.345540Z","shell.execute_reply.started":"2025-03-25T01:02:53.288684Z","shell.execute_reply":"2025-03-25T01:02:53.344482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set graph size\nplt.figure(figsize=(15, 10))\n\n# Select numerical columns\nnumeric_columns = train_data.select_dtypes(include=['int64', 'float64']).columns\n\n# Create histograms\nfor i, column in enumerate(numeric_columns):\n    if column != 'id' and column != 'rainfall':  # Exclude target variable and ID\n        plt.subplot(3, 4, i + 1)\n        sns.histplot(train_data[column], kde=True)\n        plt.title(f'Distribution of {column}')\n        plt.tight_layout()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:53.346736Z","iopub.execute_input":"2025-03-25T01:02:53.347129Z","iopub.status.idle":"2025-03-25T01:02:57.457127Z","shell.execute_reply.started":"2025-03-25T01:02:53.347091Z","shell.execute_reply":"2025-03-25T01:02:57.455939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize target variable distribution\nplt.figure(figsize=(8, 6))\nsns.countplot(x='rainfall', data=train_data)\nplt.title('Target Variable Distribution (rainfall)')\nplt.ylabel('Count')\n\nrain_counts = [train_data['rainfall'].value_counts()[0], train_data['rainfall'].value_counts()[1]]\n\nfor i, count in enumerate(rain_counts):\n    plt.text(i, count + 10, f'{count} ({count/len(train_data):.1%})', \n             ha='center', va='bottom')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:57.458236Z","iopub.execute_input":"2025-03-25T01:02:57.458721Z","iopub.status.idle":"2025-03-25T01:02:57.637381Z","shell.execute_reply.started":"2025-03-25T01:02:57.458679Z","shell.execute_reply":"2025-03-25T01:02:57.636308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check correlation between numerical variables\nplt.figure(figsize=(12, 10))\ncorr = train_data.select_dtypes(include=['int64', 'float64']).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', \n            linewidths=0.5, vmin=-1, vmax=1)\nplt.title('Correlation Matrix of Numerical Features')\nplt.tight_layout()\nplt.show()\n\n# Print correlation with target variable\ntarget_corr = corr['rainfall'].sort_values(ascending=False)\nprint(\"Features correlation with target (rainfall):\")\nprint(target_corr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:57.638438Z","iopub.execute_input":"2025-03-25T01:02:57.638771Z","iopub.status.idle":"2025-03-25T01:02:58.356067Z","shell.execute_reply.started":"2025-03-25T01:02:57.638737Z","shell.execute_reply":"2025-03-25T01:02:58.354961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Key Correlation Insights:\n\n### Relationships with Target Variable (Rainfall):\n* **Cloud (0.64)**: Cloud coverage is the strongest indicator for rainfall prediction\n* **Sunshine (-0.56)**: Decreased sunshine hours indicates increased rainfall probability\n* **Humidity (0.45)**: Higher humidity is associated with higher rainfall probability\n\n### Multicollinearity Issues:\n* Temperature, Maxtemp, and Mintemp contain almost identical information (correlation coefficients 0.97-0.99)\n* Dewpoint also has high correlation with temperature variables (0.91-0.94)\n* Cloud and Sunshine have strong negative correlation (-0.81)","metadata":{}},{"cell_type":"code","source":"# Outlier detection\nplt.figure(figsize=(15, 10))\nfor i, column in enumerate(numeric_columns):\n    if column != 'id' and column != 'rainfall':  # Exclude target variable and ID\n        plt.subplot(3, 4, i + 1)\n        sns.boxplot(x='rainfall', y=column, data=train_data)\n        plt.title(f'Boxplot of {column} by rainfall')\n        plt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:02:58.357207Z","iopub.execute_input":"2025-03-25T01:02:58.357498Z","iopub.status.idle":"2025-03-25T01:03:01.252086Z","shell.execute_reply.started":"2025-03-25T01:02:58.357473Z","shell.execute_reply":"2025-03-25T01:03:01.250885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Temporal Pattern Analysis using the 'day' variable\nif 'day' in train_data.columns:\n    # Check the data type of 'day'\n    print(f\"Data type of 'day': {train_data['day'].dtype}\")\n    \n    # If 'day' is not already in datetime format, convert it if possible\n    # (Skip this if 'day' is just a number without actual date meaning)\n    \n    # Analyze rainfall probability by day\n    plt.figure(figsize=(12, 6))\n    daily_rain_prob = train_data.groupby('day')['rainfall'].mean()\n    daily_rain_prob.plot(kind='line')\n    plt.title('Daily Rain Probability')\n    plt.xlabel('Day')\n    plt.ylabel('Probability of Rain')\n    plt.grid(True)\n    plt.show()\n    \n    # Count of rainy days vs non-rainy days by day\n    plt.figure(figsize=(12, 6))\n    rain_counts_by_day = pd.crosstab(train_data['day'], train_data['rainfall'])\n    rain_counts_by_day.plot(kind='bar', stacked=True)\n    plt.title('Rain vs No Rain Counts by Day')\n    plt.xlabel('Day')\n    plt.ylabel('Count')\n    plt.legend(['No Rain', 'Rain'])\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:01.253176Z","iopub.execute_input":"2025-03-25T01:03:01.253479Z","iopub.status.idle":"2025-03-25T01:03:04.942650Z","shell.execute_reply.started":"2025-03-25T01:03:01.253454Z","shell.execute_reply":"2025-03-25T01:03:04.941200Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Key Observations:\n* All data is numeric and mostly shows sinusoidal patterns\n   * e.g. The probability of rain exhibits periodic patterns that rise and fall according to seasons. Time series patterns and seasonality should be reflected in the model.","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering\n- Create circular encoding for wind direction (sin/cos transformation)\n- Add interaction terms between Cloud, Sunshine, and Humidity (strongest predictors)\n- Handle Temperature multicollinearity by selecting one temperature variable\n- Create dewpoint depression feature (temperature - dewpoint)","metadata":{}},{"cell_type":"code","source":"# 1. Circular encoding for wind direction (sin/cos transformation)\ndef circular_encode(df):\n    # Convert wind direction to radians (assuming wind direction is in 0-360 degree range)\n    wind_rad = np.radians(df['winddirection'])\n    \n    # Add sin/cos transformations\n    df['winddirection_sin'] = np.sin(wind_rad)\n    df['winddirection_cos'] = np.cos(wind_rad)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:04.943770Z","iopub.execute_input":"2025-03-25T01:03:04.944184Z","iopub.status.idle":"2025-03-25T01:03:04.949621Z","shell.execute_reply.started":"2025-03-25T01:03:04.944137Z","shell.execute_reply":"2025-03-25T01:03:04.948436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Add interaction terms between Cloud, Sunshine, and Humidity\ndef add_interactions(df):\n    # Convert Sunshine to numeric (assuming it's in time format)\n    if 'sunshine' in df.columns and df['sunshine'].dtype == 'object':\n        # Assuming time format is HH:MM, convert to hours\n        try:\n            df['sunshine_hours'] = df['sunshine'].apply(\n                lambda x: float(x.split(':')[0]) + float(x.split(':')[1])/60 if pd.notna(x) and ':' in str(x) else np.nan\n            )\n        except:\n            # It might be a simple numeric value\n            df['sunshine_hours'] = pd.to_numeric(df['sunshine'], errors='coerce')\n    else:\n        df['sunshine_hours'] = df['sunshine']\n    \n    # Create interaction terms\n    df['cloud_humidity'] = df['cloud'] * df['humidity']\n    df['cloud_sunshine'] = df['cloud'] * df['sunshine_hours']\n    df['humidity_sunshine'] = df['humidity'] * df['sunshine_hours']\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:04.950657Z","iopub.execute_input":"2025-03-25T01:03:04.951034Z","iopub.status.idle":"2025-03-25T01:03:04.968921Z","shell.execute_reply.started":"2025-03-25T01:03:04.950998Z","shell.execute_reply":"2025-03-25T01:03:04.967890Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Handle Temperature multicollinearity by selecting one temperature variable\ndef handle_temperature_multicollinearity(df):\n    # Check correlation between temperature variables (uncomment to run)\n    # temp_cols = ['temparature', 'maxtemp', 'mintemp']\n    # print(df[temp_cols].corr())\n    \n    # Using the basic temperature and excluding others\n    # Depending on the model, different temperature variables can be used\n    \n    # Create temperature range feature\n    df['temp_range'] = df['maxtemp'] - df['mintemp']\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:04.970011Z","iopub.execute_input":"2025-03-25T01:03:04.970486Z","iopub.status.idle":"2025-03-25T01:03:04.996049Z","shell.execute_reply.started":"2025-03-25T01:03:04.970447Z","shell.execute_reply":"2025-03-25T01:03:04.994976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Create dewpoint depression feature (temperature - dewpoint)\ndef create_dewpoint_depression(df):\n    df['dewpoint_depression'] = df['temparature'] - df['dewpoint']\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:04.996958Z","iopub.execute_input":"2025-03-25T01:03:04.997253Z","iopub.status.idle":"2025-03-25T01:03:05.017743Z","shell.execute_reply.started":"2025-03-25T01:03:04.997229Z","shell.execute_reply":"2025-03-25T01:03:05.016626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Main Feature Engineering function\ndef engineer_features(df):\n    df = df.copy()  # Preserve original data\n    \n    # Handle string format data (rainfall, sunshine, radiation, evaporation)\n    # Convert to numeric as needed\n    for col in ['rainfall', 'sunshine', 'radiation', 'evaporation']:\n        if col in df.columns and df[col].dtype == 'object':\n            df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    # Apply each Feature Engineering step\n    df = circular_encode(df)\n    df = add_interactions(df)\n    df = handle_temperature_multicollinearity(df)\n    df = create_dewpoint_depression(df)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.018721Z","iopub.execute_input":"2025-03-25T01:03:05.019006Z","iopub.status.idle":"2025-03-25T01:03:05.035286Z","shell.execute_reply.started":"2025-03-25T01:03:05.018982Z","shell.execute_reply":"2025-03-25T01:03:05.034213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply to train and test datasets\ntrain_data = engineer_features(train_data)\ntest_data = engineer_features(test_data)\n\n# Í≤∞Í≥º ÌôïÏù∏\nprint(train_data.head())\nprint(train_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.036331Z","iopub.execute_input":"2025-03-25T01:03:05.036718Z","iopub.status.idle":"2025-03-25T01:03:05.074604Z","shell.execute_reply.started":"2025-03-25T01:03:05.036680Z","shell.execute_reply":"2025-03-25T01:03:05.073708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select features and target variable\nX = train_data.drop(['rainfall'], axis=1)\ny = train_data['rainfall']\nX_test = test_data.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.075688Z","iopub.execute_input":"2025-03-25T01:03:05.076062Z","iopub.status.idle":"2025-03-25T01:03:05.083132Z","shell.execute_reply.started":"2025-03-25T01:03:05.076026Z","shell.execute_reply":"2025-03-25T01:03:05.082267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print columns with NaN values\nprint(X_test.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.084150Z","iopub.execute_input":"2025-03-25T01:03:05.084435Z","iopub.status.idle":"2025-03-25T01:03:05.102686Z","shell.execute_reply.started":"2025-03-25T01:03:05.084410Z","shell.execute_reply":"2025-03-25T01:03:05.101638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Handling Missing Value in wind direction columns\n\n#### Implemented Approach: Mode Imputation","metadata":{}},{"cell_type":"code","source":"# Fill NaN values in wind direction columns with their respective modes\nfor col in ['winddirection', 'winddirection_sin', 'winddirection_cos']:\n    X_test[col].fillna(X[col].mode()[0], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.103663Z","iopub.execute_input":"2025-03-25T01:03:05.104322Z","iopub.status.idle":"2025-03-25T01:03:05.121013Z","shell.execute_reply.started":"2025-03-25T01:03:05.104285Z","shell.execute_reply":"2025-03-25T01:03:05.119970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Pros and Cons of Mode Imputation\n\n**Pros**:\n* Simple to implement and easy to understand\n* Low computational cost\n* Effective for single missing values\n* Mode may be more appropriate than median for circular data like wind direction\n\n**Cons**:\n* Doesn't provide information about missing patterns to the model\n* Doesn't consider multivariate missing patterns\n* May introduce bias when there are multiple missing values\n\n#### Alternative Approach: Circular Mean for Directional Data\nThe commented code below shows an alternative approach that considers the circular nature of wind direction data:","metadata":{}},{"cell_type":"code","source":"# Alternative: Using circular mean for directional data\n# Wind direction is circular data (0-360 degrees) requiring special handling for mean calculation\n# import numpy as np\n# angles = np.radians(x['winddirection'].dropna())\n# mean_sin = np.mean(np.sin(angles))\n# mean_cos = np.mean(np.cos(angles))\n# mean_angle = np.degrees(np.arctan2(mean_sin, mean_cos)) % 360\n# x_test['winddirection'].fillna(mean_angle, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.122048Z","iopub.execute_input":"2025-03-25T01:03:05.122425Z","iopub.status.idle":"2025-03-25T01:03:05.137799Z","shell.execute_reply.started":"2025-03-25T01:03:05.122389Z","shell.execute_reply":"2025-03-25T01:03:05.136784Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"models = {\n    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n    \"XGBoost\": xgb.XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.05),\n    \"LightGBM\": lgb.LGBMClassifier(random_state=42, n_estimators=100),\n    \"CatBoost\": CatBoostClassifier(random_state=42, iterations=100, verbose=0)\n}\n\ndef evaluate_all_models(X, y, X_test=None, test_index=None, folds=5):\n    # Train models using StratifiedKFold CV\n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n    auc_scores = {}\n    roc_curves = {}\n    test_preds = {}\n    \n    for name, model in models.items():\n        oof_preds = np.zeros(len(y))\n        \n        if X_test is not None:\n            test_fold_preds = np.zeros((folds, len(X_test)))\n        \n        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n            \n            if isinstance(model, lgb.LGBMClassifier):\n                model.fit(X_train, y_train, \n                         eval_set=[(X_val, y_val)],\n                         callbacks=[lgb.early_stopping(50, verbose=0)])\n            elif isinstance(model, xgb.XGBClassifier):\n                model.fit(X_train, y_train,\n                         eval_set=[(X_val, y_val)],\n                         early_stopping_rounds=50,\n                         verbose=0)\n            elif isinstance(model, CatBoostClassifier):\n                model.fit(X_train, y_train,\n                         eval_set=[(X_val, y_val)],\n                         early_stopping_rounds=50,\n                         verbose=0)\n            else:\n                model.fit(X_train, y_train)\n            \n            # Save out-of-fold predictions\n            oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n            \n            # Make test predictions if test data provided\n            if X_test is not None:\n                test_fold_preds[fold] = model.predict_proba(X_test)[:, 1]\n        \n        # Calculate AUC\n        auc_score = roc_auc_score(y, oof_preds)\n        auc_scores[name] = auc_score\n        \n        # Calculate ROC curve\n        fpr, tpr, _ = roc_curve(y, oof_preds)\n        roc_curves[name] = (fpr, tpr, auc_score)\n        \n        # Average test predictions across folds\n        if X_test is not None:\n            test_preds[name] = test_fold_preds.mean(axis=0)\n        \n        print(f\"{name}: AUC = {auc_score:.4f}\")\n    \n    return auc_scores, test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.138939Z","iopub.execute_input":"2025-03-25T01:03:05.139331Z","iopub.status.idle":"2025-03-25T01:03:05.164321Z","shell.execute_reply.started":"2025-03-25T01:03:05.139295Z","shell.execute_reply":"2025-03-25T01:03:05.163365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model evaluation\nauc_scores, test_predictions = evaluate_all_models(\n    X, y, \n    X_test=X_test,\n    test_index=test_data.index,\n    folds=5\n)\n\n# Check the best model\nbest_model = max(auc_scores.items(), key=lambda x: x[1])[0]\nprint(f\"\\nThe best model: {best_model}, AUC = {auc_scores[best_model]:.4f}\")\n\nsubmission = pd.DataFrame({\n    'id': test_data.index,\n    'rainfall': test_predictions[best_model]\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSubmission file saved as 'submission.csv'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T01:03:05.165503Z","iopub.execute_input":"2025-03-25T01:03:05.165821Z","iopub.status.idle":"2025-03-25T01:03:14.945672Z","shell.execute_reply.started":"2025-03-25T01:03:05.165794Z","shell.execute_reply":"2025-03-25T01:03:14.944495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sources\n- üèÜ **Kaggle Competition:** [Binary Prediction with a Rainfall Dataset](https://www.kaggle.com/competitions/playground-series-s5e3)\n- üíª **Reference Notebook:** [üåßÔ∏èPS5E3 | Rainfall Prediction | Classification](https://www.kaggle.com/code/arunklenin/ps5e3-rainfall-prediction-classification/notebook)\n- üîó **Original data:** [Hong Kong Weather Observation Summary 2010~2019](https://www.kaggle.com/datasets/act18l/hongkongrainfall)\n- üîó **Discussion:** [Original dataset is Hong Kong data from 2015 and 2016](https://www.kaggle.com/competitions/playground-series-s5e3/discussion/566908)","metadata":{}}]}